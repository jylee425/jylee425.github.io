<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Juyong Lee</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:65%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Juyong Lee</name>
                  </p>

                  <br>
                  <p>
                    I am a PhD(/MS int.) student at KAIST, advised by <a href="https://sites.google.com/view/kiminlee"
                      target="_blank">Kimin Lee</a>.
                    I received a B.S. degree with a double major in both mathematics and computer science/engineering at
                    POSTECH.
                    I have an experience as an exchange student at Stanford.
                    Recently, I am working as a research engineer (contractor via YunoJuno) at Google DeepMind.
                  </p>

                  <p>
                    My main research interest is to build capable and reliable AI agents,
                    currently focusing on digital tasks (e.g., web tasks).
                  </p>

                  <p style="text-align:center">
                    <a href="data/Academic_CV.pdf" target="_blank">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.co.kr/citations?user=J7sqxHQAAAAJ&hl=en&oi=ao"
                      target="_blank">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://github.com/jylee425" target="_blank">Github</a>
                  </p>
                </td>
                <td class="profile-photo-cell" style="padding-right:3%;width:30%">
                  <br>
                  <a href="images/jylee_busan.png" target="_blank"><img style="width:100%;max-width:100%"
                      alt="profile photo" src="images/jylee_busan.png"></a>
                </td>
              </tr>
          </table>

          <br>
          <br>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <heading>Research Highlights</heading>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  (*: equal contribution)
                </td>
              </tr>
          </table>

          <table class="research-highlights"
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr class="research-highlight">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div style="height:100px;position:relative;">
                    <img src='images/mobilesafetybench.png' width="180" height="80">
                  </div>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://mobilesafetybench.github.io/" target="_blank">
                    <papertitle>MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control
                    </papertitle>
                  </a>

                  <br>
                  <strong>Juyong Lee*</strong>,
                  Dongyoon Hahm*,
                  June Suk Choi*,
                  W. Bradley Knox,
                  Kimin Lee
                  <br>
                  <em>AAAI 2026 (AI Alignment Track)</em>

                  <br>
                  <a href="https://mobilesafetybench.github.io/" target="_blank">project</a>
                  /
                  <a href="https://arxiv.org/abs/2410.17520" target="_blank">paper</a>
                  /
                  <a href="https://www.github.com/jylee425/mobilesafetybench" target="_blank">code</a>

                  <p>
                    We propose a new benchmark for evaluating the safety and helpfulness of agents,
                    with extensive analysis of the shortcomings of frontier LLM agents in mobile device control.
                  </p>
                </td>
              </tr>


              <tr class="research-highlight">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div style="height:100px;position:relative;">
                    <img src='images/b-moca.png' width="180" height="80">
                  </div>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://b-moca.github.io/" target="_blank">
                    <papertitle>B-MoCA: Benchmarking Mobile Device Control Agents across Diverse Configurations
                    </papertitle>
                  </a>

                  <br>
                  <strong>Juyong Lee</strong>,
                  Taywon Min,
                  Minyong An,
                  Dongyoon Hahm,
                  Haeone Lee,
                  Changyeon Kim,
                  Kimin Lee
                  <br>
                  <em>CoLLAs</em> 2025;
                  <em>ICLR</em> 2024 Workshop: GenAI4DM (<span style="color:red">spotlight presentation</span>)

                  <br>
                  <a href="https://b-moca.github.io/" target="_blank">project</a>
                  /
                  <a href="https://arxiv.org/abs/2404.16660" target="_blank">paper</a>
                  /
                  <a href="https://www.github.com/jylee425/b-moca" target="_blank">code</a>

                  <p>
                    A novel benchmark that can serve as a unified testbed for mobile device control agents
                    on performing practical daily tasks across diverse device configurations.
                  </p>
                </td>
              </tr>


              <tr class="research-highlight">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div style="height:100px;position:relative;">
                    <img src='images/lcow.png' width="180" height="50">
                  </div>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.arxiv.org/abs/2503.10689" target="_blank">
                    <papertitle>Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents
                    </papertitle>
                  </a>

                  <br>
                  Dongjun Lee*,
                  <strong>Juyong Lee*</strong>,
                  Kyuyoung Kim,
                  Jihoon Tack,
                  Jinwoo Shin,
                  Yee Whye Teh,
                  Kimin Lee
                  <br>
                  <em>ICLR</em> 2025

                  <br>
                  <a href="https://lcowiclr2025.github.io/" target="_blank">project</a>
                  /
                  <a href="https://www.arxiv.org/abs/2503.10689" target="_blank">paper</a>

                  <p>
                    A novel framework of training a contextualization module to help the decision-making of LLM agents
                    achieves the super-human performance in the WebShop benchmark.
                  </p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <img src='images/sar.png' width="180" height="90">
                  </div>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2208.14863" target="_blank">
                    <papertitle>Style-Agnostic Reinforcement Learning</papertitle>
                  </a>

                  <br>
                  <strong>Juyong Lee*</strong>,
                  Seokjun Ahn*,
                  Jaesik Park

                  <br>
                  <em>ECCV</em> 2022

                  <br>
                  <a href="https://arxiv.org/abs/2208.14863" target="_blank">paper</a>
                  /
                  <a href="https://github.com/POSTECH-CVLab/style-agnostic-RL" target="_blank">code</a>

                  <p>
                    Reinforcement learning agents become robust to the changes in the style of the image (e.g.,
                    background color)
                    by adapting to adversarially generated styles.
                  </p>
                </td>
              </tr>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:right;font-size:small;">
                        The source code is from <a href="https://github.com/jonbarron/jonbarron_website"
                          target="_blank">here</a>
                      </p>
                    </td>
                  </tr>
              </table>

        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>